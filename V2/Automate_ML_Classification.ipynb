{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a59f3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saeed\\anaconda3\\lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saeed\\anaconda3\\lib\\site-packages\\dask\\dataframe\\__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE, ADASYN, RandomOverSampler,BorderlineSMOTE, KMeansSMOTE\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB, ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, StackingClassifier, VotingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier, RidgeClassifierCV, SGDClassifier, Perceptron, PassiveAggressiveClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    " \n",
    "from sklearn.mixture import BayesianGaussianMixture, GaussianMixture\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, roc_auc_score, cohen_kappa_score, matthews_corrcoef\n",
    "from sklearn.metrics import roc_curve, auc, matthews_corrcoef\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169961dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.serif'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2571ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"smote/oversampled_datasets/\"\n",
    "dfs = {\n",
    "    'Printability' : 'Printability_resampled_df.csv',\n",
    "    'Cell_Response' : 'Cell_Response_resampled_df.csv',\n",
    "    'Scaffold_Quality' : 'Scaffold_Quality_(PxC)_resampled_df.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5fa21",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for item in dfs.keys():\n",
    "    os.makedirs(f'models/{item}', exist_ok=True)\n",
    "    \n",
    "    df_path = path + dfs[item]\n",
    "    df = pd.read_csv(df_path)\n",
    "\n",
    "    X = df.iloc[:,:-1]\n",
    "    y = df.iloc[:,-1:].values.ravel()\n",
    "    \n",
    "    unique_values = np.unique(y)\n",
    "\n",
    "    value_to_continuous = {original_value: new_value for new_value, original_value in enumerate(unique_values)}\n",
    "\n",
    "    \n",
    "    y_continuous = np.array([value_to_continuous[value] for value in y])\n",
    "    y = y_continuous\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Save the scaler\n",
    "    joblib.dump(scaler, f'models/{item}/scaler.pkl')\n",
    "\n",
    "    # Setting up GridSearchCV parameters\n",
    "    param_grid = {\n",
    "        'BernoulliNB': {\n",
    "            'model': BernoulliNB(),\n",
    "            'params': {'alpha': [0.01, 0.1, 1]}\n",
    "        },\n",
    "        'DecisionTreeClassifier': {\n",
    "            'model': DecisionTreeClassifier(random_state=42),\n",
    "            'params': {'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10],\n",
    "                      'criterion': ['gini', 'entropy', 'log_loss'], 'splitter': ['best', 'random'],\n",
    "                      'max_features': ['sqrt', 'log2']}\n",
    "        },\n",
    "        'ExtraTreeClassifier': {\n",
    "            'model': ExtraTreeClassifier(random_state=42),\n",
    "            'params': {'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10],\n",
    "                      'criterion': ['gini', 'entropy', 'log_loss'], 'splitter': ['best', 'random'],\n",
    "                      'max_features': ['sqrt', 'log2']}\n",
    "        },\n",
    "        'ExtraTreesClassifier': {\n",
    "            'model': ExtraTreesClassifier(random_state=42),\n",
    "            'params': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20],\n",
    "                      'criterion': ['gini', 'entropy', 'log_loss'], 'max_features': ['sqrt', 'log2'],\n",
    "                      'class_weight': ['balanced', 'balanced_subsample']}\n",
    "        },\n",
    "        'GaussianNB': {\n",
    "            'model': GaussianNB(),\n",
    "            'params': {}\n",
    "        },\n",
    "        'KNeighborsClassifier': {\n",
    "            'model': KNeighborsClassifier(),\n",
    "            'params': {'n_neighbors': [3, 5, 7, 10], 'weights': ['uniform', 'distance'],\n",
    "                      'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "        },\n",
    "        'LinearDiscriminantAnalysis': {\n",
    "            'model': LinearDiscriminantAnalysis(),\n",
    "            'params': {'solver': ['svd', 'lsqr', 'eigen'], 'shrinkage': ['auto', None]}\n",
    "        },\n",
    "        'LogisticRegression': {\n",
    "            'model': LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42),\n",
    "            'params': {'C': [0.01, 0.1, 1], 'penalty': ['l1', 'l2', 'elasticnet', None], 'class_weight': ['balanced', None]}\n",
    "        },\n",
    "        'MLPClassifier': {\n",
    "            'model': MLPClassifier(random_state=42),\n",
    "            'params': {'hidden_layer_sizes': [(50,), (100,)], 'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                       'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "                        'max_iter': [1000, 10000]}\n",
    "        },\n",
    "        'RandomForestClassifier': {\n",
    "            'model': RandomForestClassifier(random_state=42),\n",
    "            'params': {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 50, 80], \n",
    "                       'criterion': ['gini', 'entropy', 'log_loss'], 'max_features': ['sqrt', 'log2', None],\n",
    "                       'class_weight': ['balanced', 'balanced_subsample']}\n",
    "        },\n",
    "        'SVC': {\n",
    "            'model': SVC(random_state=42, probability=True),\n",
    "            'params': {'C': [0.01, 0.1, 1], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "                      'gamma': ['scale', 'auto']}\n",
    "        },\n",
    "        'GaussianProcessClassifier': {\n",
    "            'model': GaussianProcessClassifier(random_state=42),\n",
    "            'params': {'multi_class': ['one_vs_rest']}\n",
    "        },\n",
    "        'GradientBoostingClassifier': {\n",
    "            'model': GradientBoostingClassifier(random_state=42),\n",
    "            'params': {'n_estimators': [100, 200], 'learning_rate': [0.001, 0.01, 0.1], 'max_depth': [3, 5, 10],\n",
    "                      'loss': ['log_loss', 'exponential'], 'criterion': ['friedman_mse', 'squared_error'], \n",
    "                       'max_features': ['sqrt', 'log2', None]}\n",
    "        },\n",
    "        'AdaBoostClassifier': {\n",
    "            'model': AdaBoostClassifier(random_state=42),\n",
    "            'params': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'algorithm': ['SAMME', 'SAMME.R']}\n",
    "        },\n",
    "        'BaggingClassifier': {\n",
    "            'model': BaggingClassifier(random_state=42),\n",
    "            'params': {'n_estimators': [10, 50, 100], 'max_samples': [0.5, 1.0], 'max_features': [0.5, 1.0]}\n",
    "        },\n",
    "        'ComplementNB': {\n",
    "            'model': ComplementNB(),\n",
    "            'params': {'alpha': [0.01, 0.1, 1]}\n",
    "        },\n",
    "        'DummyClassifier': {\n",
    "            'model': DummyClassifier(),\n",
    "            'params': {'strategy': ['most_frequent', 'prior', 'stratified', 'uniform', 'constant']}\n",
    "        },\n",
    "        'HistGradientBoostingClassifier': {\n",
    "            'model': HistGradientBoostingClassifier(random_state=42),\n",
    "            'params': {'max_iter': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [None, 10, 20],\n",
    "                      'interaction_cst': ['pairwise', 'no_interactions']}\n",
    "        },\n",
    "        'LabelPropagation': {\n",
    "            'model': LabelPropagation(),\n",
    "            'params': {'gamma': [0.01, 0.1, 1], 'kernel': ['knn', 'rbf']}\n",
    "        },\n",
    "        'LabelSpreading': {\n",
    "            'model': LabelSpreading(),\n",
    "            'params': {'gamma': [0.01, 0.1, 1], 'kernel': ['knn', 'rbf'], 'n_neighbors': [7, 9, 15]}\n",
    "        },\n",
    "        'LogisticRegressionCV': {\n",
    "            'model': LogisticRegressionCV(multi_class='multinomial', random_state=42),\n",
    "            'params': {'Cs': [10, 20], 'cv': [3, 5], 'max_iter': [10000],\n",
    "                       'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
    "        },\n",
    "        'MultinomialNB': {\n",
    "            'model': MultinomialNB(),\n",
    "            'params': {'alpha': [0.01, 0.1, 1]}\n",
    "        },\n",
    "        'NuSVC': {\n",
    "            'model': NuSVC(probability=True, random_state=42), 'gamma': ['scale', 'auto'], 'class_weight': [None, 'balanced'],\n",
    "            'params': {'nu': [0.1, 0.5], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "        },\n",
    "        'QuadraticDiscriminantAnalysis': {\n",
    "            'model': QuadraticDiscriminantAnalysis(),\n",
    "            'params': {'reg_param': [0.0, 0.1, 0.5]}\n",
    "        },\n",
    "        'RadiusNeighborsClassifier': {\n",
    "            'model': RadiusNeighborsClassifier(),\n",
    "            'params': {\n",
    "                'radius': [5, 10, 15], \n",
    "                'weights': ['uniform', 'distance'],\n",
    "                'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'outlier_label': [None, 'most_frequent']\n",
    "            }\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'model': XGBClassifier(random_state=42),\n",
    "            'params': {\n",
    "                'n_estimators': [100, 200], 'booster': ['gbtree', 'gblinear', 'dart'], \n",
    "                'learning_rate': [0.001, 0.01, 0.1], 'importance_type': ['gain', 'weight', 'cover', 'total_gain', 'total_cover'],\n",
    "                'max_depth': [3, 5, 9]\n",
    "            }\n",
    "        },\n",
    "        'SGDClassifier': {\n",
    "            'model': SGDClassifier(random_state=42, loss='log_loss'),\n",
    "            'params': {'penalty': ['l2', 'l1', 'elasticnet', None], 'alpha': [0.0001, 0.001, 0.01], 'class_weight': ['balanced', None],\n",
    "                      'loss': ['log_loss', 'modified_huber', 'squared_hinge', 'perceptron',# 'hinge', \n",
    "                           'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                       'max_iter': [10000]\n",
    "                      }\n",
    "        },\n",
    "        'CatBoost': {\n",
    "            'model': CatBoostClassifier(verbose=0, random_state=42),\n",
    "            'params': {\n",
    "                'iterations': [100, 200],\n",
    "                'learning_rate': [0.01, 0.1],\n",
    "                'depth': [3, 5]\n",
    "            }\n",
    "        },\n",
    "        'LightGBM': {\n",
    "            'model': LGBMClassifier(random_state=42, verbose=-1),\n",
    "            'params': {\n",
    "                'n_estimators': [100, 200], 'boosting_type': ['gbdt', 'dart', 'rf'], 'class_weight': ['balanced', None],\n",
    "                'learning_rate': [0.001, 0.01, 0.1],\n",
    "                'max_depth': [3, 5, 9],\n",
    "                'num_leaves': [31, 62]\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Cross-validation setup\n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "    # DataFrame for results and ROC data\n",
    "    globals()[f'{item}_result_df'] = pd.DataFrame(columns=['Classifier', 'Best Params', 'Precision', 'Recall', \n",
    "                                                           'Accuracy', 'F1 Score', 'AUC', 'Kappa', 'MCC'])\n",
    "    roc_data_list = []\n",
    "\n",
    "    # Binarize the output for ROC curve\n",
    "    y_test_binarized = label_binarize(y_test, classes=np.unique(y_test))\n",
    "    n_classes = y_test_binarized.shape[1]\n",
    "\n",
    "    # Figure for combined ROC Curves\n",
    "    plt.figure(figsize=(20, 16))\n",
    "\n",
    "    for name, config in param_grid.items():\n",
    "        print(f\"*** Processing {name} ***\")\n",
    "        grid_search = GridSearchCV(config['model'], config['params'], cv=StratifiedKFold(n_splits=10), scoring='accuracy', verbose=1)\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Predictions and evaluations\n",
    "        y_pred = grid_search.predict(X_test_scaled)\n",
    "        y_proba = grid_search.predict_proba(X_test_scaled)\n",
    "\n",
    "        precision = precision_score(y_test, y_pred, average='macro')\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        auc_score = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "        # Update results DataFrame\n",
    "        globals()[f'{item}_result_df'].loc[len(globals()[f'{item}_result_df'].index)] = [name, grid_search.best_params_, precision, recall, accuracy, f1, auc_score, kappa, mcc]\n",
    "\n",
    "        # Separate ROC curve plotting\n",
    "        fpr, tpr, _ = roc_curve(y_test_binarized.ravel(), y_proba.ravel())\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'{name} (area = {roc_auc:.4f})')\n",
    "\n",
    "        roc_data = {'Classifier': name, 'FPR': fpr.tolist(), 'TPR': tpr.tolist(), 'AUC': roc_auc}\n",
    "        roc_data_list.append(roc_data)\n",
    "\n",
    "    # Finalizing the combined ROC curve plot\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.title(f'{item} ROC Curves', fontsize=20, fontweight='bold')\n",
    "    plt.xticks(fontsize=14)  \n",
    "    plt.yticks(fontsize=14) \n",
    "    plt.legend(loc=\"lower right\", fontsize=13)\n",
    "    plt.show()\n",
    "\n",
    "    # Convert ROC data list to DataFrame for future use\n",
    "    globals()[f'{item}_roc_df'] = pd.DataFrame(roc_data_list)\n",
    "    globals()[f'{item}_roc_df'].to_csv(f'models/{item}/{item}_roc.csv')\n",
    "\n",
    "    # Save the results DataFrame\n",
    "    globals()[f'{item}_result_df'].to_csv(f'models/{item}/{item}_results.csv')\n",
    "    \n",
    "    # Save ROC data to JSON\n",
    "    with open(f'models/{item}/{item}_roc.json', 'w') as f:\n",
    "        json.dump(roc_data_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0341997c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ace4b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27f9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2cd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843b4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a5228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
